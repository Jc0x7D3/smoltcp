# 日志

## 第三周 9.29





## 第五周 10.08





## 第六周 10.15

阅读了axnet和部分smoltcp的代码。

axnet笔记：

WouldBlock：表示下层一个任务未完成，上层需要重试。在nonblock模式中，下层函数返回WouldBlock上层会直接也返回WouldBlock；反之，上层会多次{yield; 重试;}直到成功。

和异步的差距：

- 多次重试失败，上下文切换次数较多
- 函数返回WouldBlock的控制流必须可重复执行



```rust
    pub fn send(&self, buf: &[u8]) -> AxResult<usize> {
        if self.is_connecting() {
            // 等待连接完成
            return Err(AxError::WouldBlock);
        } else if !self.is_connected() {
            return ax_err!(NotConnected, "socket send() failed");
        }

        // SAFETY: `self.handle` should be initialized in a connected socket.
        let handle = unsafe { self.handle.get().read().unwrap() };
        self.block_on(|| {
            SOCKET_SET.with_socket_mut::<tcp::Socket, _, _>(handle, |socket| {
                if !socket.is_active() || !socket.may_send() {
                    // closed by remote
                    ax_err!(ConnectionReset, "socket send() failed")
                } else if socket.can_send() {
                    // connected, and the tx buffer is not full
                    // TODO: use socket.send(|buf| {...})
                    let len = socket
                        .send_slice(buf)
                        .map_err(|_| ax_err_type!(BadState, "socket send() failed"))?;
                    Ok(len)
                } else {
                    // tx buffer is full
                    Err(AxError::WouldBlock)
                }
            })
        })
    }


    fn block_on<F, T>(&self, mut f: F) -> AxResult<T>
    where
        F: FnMut() -> AxResult<T>,
    {
        if self.is_nonblocking() {
            f()
        } else {
            loop {
                #[cfg(feature = "monolithic")]
                if axprocess::signal::current_have_signals() {
                    return Err(AxError::Interrupted);
                }

                SOCKET_SET.poll_interfaces();
                match f() {
                    Ok(t) => return Ok(t),
                    Err(AxError::WouldBlock) => axtask::yield_now(),
                    Err(e) => return Err(e),
                }
            }
        }
    }



    pub fn poll<D>(
        &mut self,
        timestamp: Instant,
        device: &mut D,
        sockets: &mut SocketSet<'_>,
    ) -> bool
    where
        D: Device + ?Sized,
    {
        self.inner.now = timestamp;

        #[cfg(feature = "_proto-fragmentation")]
        self.fragments.assembler.remove_expired(timestamp);

        match self.inner.caps.medium {
            #[cfg(feature = "medium-ieee802154")]
            Medium::Ieee802154 =>
            {
                #[cfg(feature = "proto-sixlowpan-fragmentation")]
                if self.sixlowpan_egress(device) {
                    return true;
                }
            }
            #[cfg(any(feature = "medium-ethernet", feature = "medium-ip"))]
            _ =>
            {
                #[cfg(feature = "proto-ipv4-fragmentation")]
                if self.ipv4_egress(device) {
                    return true;
                }
            }
        }

        let mut readiness_may_have_changed = false;

        loop {
            let mut did_something = false;
            did_something |= self.socket_ingress(device, sockets);
            did_something |= self.socket_egress(device, sockets);

            #[cfg(feature = "proto-igmp")]
            {
                did_something |= self.igmp_egress(device);
            }

            if did_something {
                readiness_may_have_changed = true;
            } else {
                break;
            }
        }

        readiness_may_have_changed
    }



    fn socket_egress<D>(&mut self, device: &mut D, sockets: &mut SocketSet<'_>) -> bool
    where
        D: Device + ?Sized,
    {
        let _caps = device.capabilities();

        enum EgressError {
            Exhausted,
            Dispatch(DispatchError),
        }

        let mut emitted_any = false;
        for item in sockets.items_mut() {
            if !item
                .meta
                .egress_permitted(self.inner.now, |ip_addr| self.inner.has_neighbor(&ip_addr))
            {
                continue;
            }

            let mut neighbor_addr = None;
            let mut respond = |inner: &mut InterfaceInner, meta: PacketMeta, response: Packet| {
                neighbor_addr = Some(response.ip_repr().dst_addr());
                let t = device.transmit(inner.now).ok_or_else(|| {
                    net_debug!("failed to transmit IP: device exhausted");
                    EgressError::Exhausted
                })?;

                inner
                    .dispatch_ip(t, meta, response, &mut self.fragmenter)
                    .map_err(EgressError::Dispatch)?;

                emitted_any = true;

                Ok(())
            };

            let result = match &mut item.socket {
                #[cfg(feature = "socket-raw")]
                Socket::Raw(socket) => socket.dispatch(&mut self.inner, |inner, (ip, raw)| {
                    respond(
                        inner,
                        PacketMeta::default(),
                        Packet::new(ip, IpPayload::Raw(raw)),
                    )
                }),
                ......
            };

            match result {
                Err(EgressError::Exhausted) => break, // Device buffer full.
                Err(EgressError::Dispatch(_)) => {
                    // `NeighborCache` already takes care of rate limiting the neighbor discovery
                    // requests from the socket. However, without an additional rate limiting
                    // mechanism, we would spin on every socket that has yet to discover its
                    // neighbor.
                    item.meta.neighbor_missing(
                        self.inner.now,
                        neighbor_addr.expect("non-IP response packet"),
                    );
                }
                Ok(()) => {}
            }
        }
        emitted_any
    }
}
```



下周安排：

- 补全之前的文档
- 尝试性能测量工具和方法，测量各种传输速率下：
  - CPU占用？
  - 切换次数？
  - 切换所占的时间？
  - 和异步的比较？







## 第七周 10.22

### 速率测试

#### 接口层

直接构造链路层报文给接口层发送，为理论最高速率。

```sh
make A=apps/net/bwbench SMP=1 NET=y LOG=debug run
```

<img src="C:\Users\19513\AppData\Roaming\Typora\typora-user-images\image-20241021225415551.png" alt="image-20241021225415551" style="zoom:50%;" />



#### 传输层

```sh
make A=apps/c/iperf SMP=1 NET=y BLK=y ARCH=x86_64 LOG=error run
```

在WSL中：

```sh
iperf3 -c 127.0.0.1 -p 5555 -R
```

<img src="C:\Users\19513\AppData\Roaming\Typora\typora-user-images\image-20241021225850254.png" alt="image-20241021225850254" style="zoom:50%;" />

```sh
iperf3 -uc 127.0.0.1 -p 5555 -b 1000M -l 1472 -R
```

<img src="https://s2.loli.net/2024/10/21/wu1B4OnrZXIAGl2.png" alt="image-20241021231259037" style="zoom:50%;" />

### 发现BUG

```sh
iperf3 -uc 127.0.0.1 -p 5555 -b 1000M -l 1480 -R
```

<img src="https://s2.loli.net/2024/10/21/4jk6BPpuqrOxsVz.png" alt="image-20241021231334558" style="zoom:50%;" />

panicked at modules/axnet/src/smoltcp_impl/mod.rs:290:51: called `Result::unwrap()` on an `Err` value: InvalidParam

发送1475<=len<=1486的UDP报文时，内核会panic

**临时解决方案：**限制UDP发送大小到保守的值（传输层分片）

<img src="C:\Users\19513\AppData\Roaming\Typora\typora-user-images\image-20241022005600962.png" alt="image-20241022005600962" style="zoom:50%;" />

**提Issue：**[Bug: Special length UDP packets cause kernel panic · Issue #4 · Starry-OS/axnet](https://github.com/Starry-OS/axnet/issues/4)



## 第八周 10.29

### 速率测试

#### 真实网卡

**测试结构：**

```
   WSL     172.26.218.77    172.26.208.1   Laptop    192.168.1.3             192.168.1.2
Starry-OS <------------------------------> Windows <---100Mbps--->  Router <-------------> Armbian
  iperf3       :5555                      portproxy -> :22223       
           
```

**Windows:**

```bash
netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=22223 connectaddress=172.26.218.77 connectport=5555
```

**Armbian:**

TCP测试：x86-64下，收发均可以接近硬件极限100Mbps

<img src="https://s2.loli.net/2024/10/28/qfo3V2HQxZkg5ps.png" alt="image-20241028210909661" style="zoom:50%;" />

<img src="https://s2.loli.net/2024/10/28/fEbzPksjHSJvngT.png" alt="image-20241028210855049" style="zoom:50%;" />

riscv64下，发送速率降到80Mbps左右。

<img src="https://s2.loli.net/2024/10/28/npv7AOWjwE9QkgX.png" alt="image-20241028221608411" style="zoom:50%;" />

<img src="https://s2.loli.net/2024/10/28/unfoUON817abpXx.png" alt="image-20241028221622423" style="zoom:50%;" />

UDP测试：失败。netsh不支持转发UDP流量，[sokit](https://download.csdn.net/download/k3108001263/11032403)也失败

<img src="https://s2.loli.net/2024/10/28/Gtw7Vrd8e9BoQfS.png" alt="image-20241028211911302" style="zoom:50%;" />





<img src="https://s2.loli.net/2024/10/28/KtJORPdQ3a9F51h.png" alt="image-20241028201231768" style="zoom:50%;" />